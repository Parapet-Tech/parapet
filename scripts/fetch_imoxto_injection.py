# Copyright 2026 The Parapet Project
# SPDX-License-Identifier: Apache-2.0

"""
Download imoxto/prompt_injection_cleaned_dataset-v2 from HuggingFace
and convert to parapet eval YAML format.

Source: https://huggingface.co/datasets/imoxto/prompt_injection_cleaned_dataset-v2
Cleaned prompt injection dataset. Mixed labels (injection/benign).
Used by ProtectAI for prompt injection detection training.

TODO: The benign split (labels=0) is corrupt — entries labeled benign are actually
prompt injection attacks (e.g. "I have been PWNED", "Disregard other instructions").
Currently only the attack split is usable. Investigate whether the labels field is
inverted or if a different split/version fixes this. Until then, imoxto_benign.yaml
is excluded from training (see PROTECTAI_FILES in train_l1.py).
"""

from datasets import load_dataset
import random
import yaml
import sys

MAX_SAMPLES = 2000


def main():
    print("Loading imoxto/prompt_injection_cleaned_dataset-v2...", file=sys.stderr)
    ds = load_dataset("imoxto/prompt_injection_cleaned_dataset-v2", split="train")
    print(f"Total rows: {len(ds)}", file=sys.stderr)

    attacks = []
    benign = []
    seen = set()
    for i, row in enumerate(ds):
        text = (row.get("text") or row.get("prompt") or "").strip()
        # Strip null bytes and other control chars that break YAML
        text = text.replace("\x00", "")
        if not text or text in seen:
            continue
        seen.add(text)

        # Dataset uses 'labels' field: 1=injection, 0=benign
        label_raw = row.get("labels", row.get("label", ""))
        if label_raw in (1, "1", "INJECTION"):
            attacks.append({
                "id": f"imoxto-{i:04d}",
                "layer": "l1",
                "label": "malicious",
                "description": "imoxto prompt injection",
                "content": text,
            })
        elif label_raw in (0, "0", "LEGIT"):
            benign.append({
                "id": f"imoxto-{i:04d}",
                "layer": "l1",
                "label": "benign",
                "description": "imoxto benign",
                "content": text,
            })

    print(f"Attacks (deduplicated): {len(attacks)}", file=sys.stderr)
    print(f"Benign (deduplicated): {len(benign)}", file=sys.stderr)

    # Sample down large sets
    if len(attacks) > MAX_SAMPLES:
        random.seed(42)
        attacks = random.sample(attacks, MAX_SAMPLES)
        for j, case in enumerate(attacks):
            case["id"] = f"imoxto-atk-{j:04d}"
        print(f"  sampled attacks to {MAX_SAMPLES}", file=sys.stderr)

    if len(benign) > MAX_SAMPLES:
        random.seed(43)
        benign = random.sample(benign, MAX_SAMPLES)
        for j, case in enumerate(benign):
            case["id"] = f"imoxto-ben-{j:04d}"
        print(f"  sampled benign to {MAX_SAMPLES}", file=sys.stderr)

    if attacks:
        path = "schema/eval/opensource_imoxto_attacks.yaml"
        with open(path, "w", encoding="utf-8") as f:
            f.write(
                "# imoxto/prompt_injection_cleaned_dataset-v2 — attack cases\n"
                "# Source: https://huggingface.co/datasets/imoxto/prompt_injection_cleaned_dataset-v2\n"
                "# Auto-generated by scripts/fetch_imoxto_injection.py\n\n"
            )
            yaml.dump(attacks, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
        print(f"  wrote {len(attacks)} attacks to {path}", file=sys.stderr)

    if benign:
        path = "schema/eval/opensource_imoxto_benign.yaml"
        with open(path, "w", encoding="utf-8") as f:
            f.write(
                "# imoxto/prompt_injection_cleaned_dataset-v2 — benign cases\n"
                "# Source: https://huggingface.co/datasets/imoxto/prompt_injection_cleaned_dataset-v2\n"
                "# Auto-generated by scripts/fetch_imoxto_injection.py\n\n"
            )
            yaml.dump(benign, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
        print(f"  wrote {len(benign)} benign to {path}", file=sys.stderr)


if __name__ == "__main__":
    main()
