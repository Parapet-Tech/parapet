"""
Download Hello-SimpleAI/HC3 (Human ChatGPT Comparison Corpus) from HuggingFace
and convert to parapet eval YAML format.

Source: https://huggingface.co/datasets/Hello-SimpleAI/HC3
Real user questions across domains (finance, medicine, open_qa, reddit_eli5, wiki_csai).
All benign. Good for L1 training negative class and L3-inbound false-positive testing.
"""

from datasets import load_dataset
import yaml
import sys


def main():
    print("Loading Hello-SimpleAI/HC3...", file=sys.stderr)
    ds = load_dataset("Hello-SimpleAI/HC3", "all", split="train", trust_remote_code=True)
    print(f"Total rows: {len(ds)}", file=sys.stderr)

    cases = []
    seen = set()
    for i, row in enumerate(ds):
        text = (row.get("question") or "").strip()
        if not text or text in seen:
            continue
        seen.add(text)
        source = row.get("source", "unknown")
        cases.append({
            "id": f"hc3-{i:04d}",
            "layer": "l3_inbound",
            "label": "benign",
            "description": f"HC3 {source}",
            "content": text,
        })

    print(f"Benign cases (deduplicated): {len(cases)}", file=sys.stderr)
    path = "schema/eval/opensource_hc3_benign.yaml"
    with open(path, "w", encoding="utf-8") as f:
        f.write(
            "# Hello-SimpleAI/HC3 â€” real user questions (all benign)\n"
            "# Source: https://huggingface.co/datasets/Hello-SimpleAI/HC3\n"
            "# Domains: finance, medicine, open_qa, reddit_eli5, wiki_csai\n"
            "# Auto-generated by scripts/fetch_hc3.py\n\n"
        )
        yaml.dump(cases, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
    print(f"  wrote {len(cases)} cases to {path}", file=sys.stderr)


if __name__ == "__main__":
    main()
