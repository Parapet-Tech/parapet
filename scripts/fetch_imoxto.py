# Copyright 2026 The Parapet Project
# SPDX-License-Identifier: Apache-2.0

"""
Download imoxto/prompt_injection_cleaned_dataset-v2 from HuggingFace
and convert to parapet eval YAML format.

Source: https://huggingface.co/datasets/imoxto/prompt_injection_cleaned_dataset-v2

Part of the ProtectAI recipe for prompt injection detection.
535K rows total. Labels: 0=benign, 1=injection.
We fetch label=1 (attack) rows only, capped at MAX_ROWS.
"""

import requests
import yaml
import sys

API = "https://datasets-server.huggingface.co/rows"
DATASET = "imoxto/prompt_injection_cleaned_dataset-v2"
CONFIG = "default"
SPLIT = "train"
MAX_ROWS = 1000
BATCH = 100


def fetch_rows():
    """Fetch up to MAX_ROWS attack rows (label=1) from the dataset."""
    rows = []
    offset = 0
    seen = set()
    # Dataset is 535K rows; we need to page through and filter label=1.
    # Over-fetch to compensate for label=0 rows we skip.
    max_api_calls = 200  # safety limit: 200 * 100 = 20K rows scanned
    api_calls = 0
    while len(rows) < MAX_ROWS and api_calls < max_api_calls:
        resp = requests.get(
            API,
            params={
                "dataset": DATASET,
                "config": CONFIG,
                "split": SPLIT,
                "offset": offset,
                "length": BATCH,
            },
            timeout=30,
        )
        resp.raise_for_status()
        data = resp.json()
        batch = data.get("rows", [])
        if not batch:
            break
        for item in batch:
            if len(rows) >= MAX_ROWS:
                break
            row = item.get("row", {})
            label = row.get("labels", 0)
            if label != 1:
                continue
            text = str(row.get("text") or "").strip()
            if not text or len(text) < 10:
                continue
            # Deduplicate
            if text in seen:
                continue
            seen.add(text)
            rows.append(text)
        offset += BATCH
        api_calls += 1
        if len(rows) % 200 < BATCH:
            print(f"  fetched {len(rows)} attack rows ({offset} scanned)...", file=sys.stderr)
        if len(batch) < BATCH:
            break
    return rows


def main():
    print("Fetching imoxto/prompt_injection_cleaned_dataset-v2...", file=sys.stderr)
    rows = fetch_rows()
    print(f"Total attack rows fetched: {len(rows)}", file=sys.stderr)

    cases = []
    for i, text in enumerate(rows):
        # Truncate very long entries
        content = text
        if len(content) > 4000:
            content = content[:4000] + "\n[truncated]"

        cases.append(
            {
                "id": f"imoxto-{i:04d}",
                "layer": "l1",
                "label": "malicious",
                "description": f"imoxto prompt_injection_cleaned row {i}",
                "content": content,
            }
        )

    print(f"Attack cases: {len(cases)}", file=sys.stderr)

    path = "schema/eval/opensource_imoxto_attacks.yaml"
    with open(path, "w", encoding="utf-8") as f:
        f.write(
            "# imoxto/prompt_injection_cleaned_dataset-v2 â€” prompt injection attacks\n"
            "# Source: https://huggingface.co/datasets/imoxto/prompt_injection_cleaned_dataset-v2\n"
            "# Part of ProtectAI recipe (attack split, label=1)\n"
            f"# Sampled {len(cases)} attack cases\n"
            "# Auto-generated by scripts/fetch_imoxto.py\n\n"
        )
        yaml.dump(cases, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
    print(f"Wrote {len(cases)} cases to {path}", file=sys.stderr)
    print("Done.", file=sys.stderr)


if __name__ == "__main__":
    main()
