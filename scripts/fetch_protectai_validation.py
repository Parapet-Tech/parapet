# Copyright 2026 The Parapet Project
# SPDX-License-Identifier: Apache-2.0

"""
Download protectai/prompt-injection-validation from HuggingFace
and convert to parapet eval YAML format.

Source: https://huggingface.co/datasets/protectai/prompt-injection-validation

ProtectAI's own validation set for prompt injection detection.
3,227 samples across 7 splits: InjecGuard, Spikee, BIPIA, WildGuard,
Deepset, and not_inject. Labels: 0=benign, 1=injection.

We fetch all splits and emit separate attack/benign YAML files.
"""

import requests
import yaml
import sys

API = "https://datasets-server.huggingface.co/rows"
DATASET = "protectai/prompt-injection-validation"
CONFIG = "default"
SPLITS = [
    "InjecGuard_valid",
    "spikee",
    "bipia_text",
    "bipia_code",
    "not_inject",
    "wildguard",
    "deepset",
]
BATCH = 100


def fetch_split(split_name):
    """Fetch all rows from a split."""
    rows = []
    offset = 0
    while True:
        resp = requests.get(
            API,
            params={
                "dataset": DATASET,
                "config": CONFIG,
                "split": split_name,
                "offset": offset,
                "length": BATCH,
            },
            timeout=30,
        )
        resp.raise_for_status()
        data = resp.json()
        batch = data.get("rows", [])
        if not batch:
            break
        for item in batch:
            row = item.get("row", {})
            rows.append(row)
        offset += len(batch)
        if len(batch) < BATCH:
            break
    return rows


def main():
    print("Fetching protectai/prompt-injection-validation...", file=sys.stderr)

    attacks = []
    benign = []
    seen = set()

    for split_name in SPLITS:
        print(f"  Split: {split_name}...", file=sys.stderr)
        rows = fetch_split(split_name)
        split_atk = 0
        split_ben = 0
        for row in rows:
            text = str(row.get("text") or "").strip()
            label = row.get("label", 0)
            source = row.get("source", split_name)
            if not text or len(text) < 10:
                continue
            if text in seen:
                continue
            seen.add(text)

            case = {
                "id": f"protectai-val-{len(attacks) + len(benign):04d}",
                "layer": "l1",
                "label": "malicious" if label == 1 else "benign",
                "description": f"protectai validation split={split_name} source={source}",
                "content": text[:4000],
            }
            if label == 1:
                attacks.append(case)
                split_atk += 1
            else:
                benign.append(case)
                split_ben += 1
        print(f"    {split_atk} atk, {split_ben} ben", file=sys.stderr)

    print(f"\nTotal: {len(attacks)} attacks, {len(benign)} benign", file=sys.stderr)

    header = (
        "# protectai/prompt-injection-validation\n"
        "# Source: https://huggingface.co/datasets/protectai/prompt-injection-validation\n"
        "# ProtectAI's validation set: InjecGuard, Spikee, BIPIA, WildGuard, Deepset\n"
        "# Auto-generated by scripts/fetch_protectai_validation.py\n"
    )

    path_atk = "schema/eval/opensource_protectai_val_attacks.yaml"
    with open(path_atk, "w", encoding="utf-8") as f:
        f.write(header + f"# {len(attacks)} attack cases\n\n")
        yaml.dump(attacks, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
    print(f"Wrote {len(attacks)} cases to {path_atk}", file=sys.stderr)

    path_ben = "schema/eval/opensource_protectai_val_benign.yaml"
    with open(path_ben, "w", encoding="utf-8") as f:
        f.write(header + f"# {len(benign)} benign cases\n\n")
        yaml.dump(benign, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
    print(f"Wrote {len(benign)} cases to {path_ben}", file=sys.stderr)

    print("Done.", file=sys.stderr)


if __name__ == "__main__":
    main()
