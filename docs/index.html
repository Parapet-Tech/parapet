<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Parapet is an open-source LLM security proxy that stops prompt injection, tool abuse, and data exfiltration before they reach your model.">
    <title>Parapet — LLM Security Proxy</title>
    <link rel="canonical" href="https://parapet.tech/">
    <meta property="og:title" content="Parapet — LLM Security Proxy">
    <meta property="og:description" content="Stop prompt injection before it reaches your LLM. Open-source proxy firewall with layered defense, config-driven via YAML.">
    <meta property="og:url" content="https://parapet.tech/">
    <meta property="og:type" content="website">
    <meta property="og:site_name" content="Parapet">
    <meta property="og:image" content="https://parapet.tech/imgs/pp6.png">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Parapet — LLM Security Proxy">
    <meta name="twitter:description" content="Stop prompt injection before it reaches your LLM. Open-source proxy firewall with layered defense.">
    <meta name="twitter:image" content="https://parapet.tech/imgs/pp6.png">
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "SoftwareApplication",
      "name": "Parapet",
      "applicationCategory": "SecurityApplication",
      "description": "Open-source LLM security proxy that stops prompt injection, tool abuse, and data exfiltration.",
      "url": "https://parapet.tech/",
      "operatingSystem": "Cross-platform",
      "offers": {
        "@type": "Offer",
        "price": "0",
        "priceCurrency": "USD"
      }
    }
    </script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">
    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="stylesheet" href="parapet.css">
</head>
<body>

    <!-- Nav -->
    <nav aria-label="Main navigation">
        <span class="nav-brand">parapet</span>
        <ul class="nav-links">
            <li><a href="#how-it-works">How It Works</a></li>
            <li><a href="#quickstart">Quickstart</a></li>
            <li><a href="https://arxiv.org/abs/2602.11247">Paper</a></li>
            <li><a href="https://github.com/Parapet-Tech/parapet" aria-label="Parapet on GitHub">GitHub</a></li>
        </ul>
    </nav>

    <main>

    <!-- Hero -->
    <section class="hero" id="hero">
        <img src="imgs/p1.png" alt="" class="hero-bg" role="presentation">
        <div class="container">
            <p class="hero-label">Open-source LLM security</p>
            <h1>Stop prompt injection <em>before</em> it reaches your LLM</h1>
            <p class="hero-sub">Parapet is a transparent proxy firewall that scans every request and response for prompt injection, tool abuse, and data exfiltration. Config-driven. Self-hosted. Three lines to integrate.</p>
            <div class="hero-install">
                <span aria-hidden="true">$</span>
                <code>pip install parapet</code>
            </div>
            <div class="hero-ctas">
                <a href="https://github.com/Parapet-Tech/parapet" class="btn btn-primary">View on GitHub</a>
                <a href="#quickstart" class="btn btn-secondary">Get Started</a>
            </div>
        </div>
    </section>

    <!-- Problem -->
    <section id="problem">
        <div class="container">
            <p class="section-label">The Problem</p>
            <h2>LLMs trust everything they read</h2>
            <p class="section-desc">Your model can't tell the difference between your instructions and an attacker's. Every tool call, every retrieved document, every user message is an attack surface.</p>
            <div class="stats-grid">
                <div class="stat">
                    <div class="stat-number">0</div>
                    <div class="stat-label">LLM providers offer deterministic multi-turn prompt injection detection at the API level</div>
                </div>
                <div class="stat">
                    <div class="stat-number">5 min</div>
                    <div class="stat-label">from install to your first blocked attack with Parapet</div>
                </div>
                <div class="stat">
                    <div class="stat-number">98.6%</div>
                    <div class="stat-label">F1 on prompt injection detection — sub-microsecond, no LLM call</div>
                </div>
            </div>
        </div>
    </section>

    <!-- How It Works — Layer Pipeline -->
    <section id="how-it-works">
        <div class="container">
            <p class="section-label">How It Works</p>
            <h2>Layered defense in the request pipeline</h2>
            <p class="section-desc">Parapet sits between your app and the LLM provider. Every message passes through a stack of security layers before it reaches the model — and again before the response reaches your app.</p>
            <div class="pipeline-roundtrip" role="img" aria-label="Request pipeline: Your App sends a request through L0 Normalize, L1 Classify, L3 Inbound Block, and L4 Multi-Turn scoring, then to the LLM Provider. The response passes through L3 Outbound Constrain and L5a Redact before returning to your app.">
                <div class="pipeline-row-label">Request</div>
                <div class="pipeline-row">
                    <div class="pipeline-node node-start">
                        <div class="pipeline-node-name">Your App</div>
                        <div class="pipeline-node-desc">SDK intercepts</div>
                    </div>
                    <div class="pipeline-arrow" aria-hidden="true">&#8594;</div>
                    <div class="pipeline-node">
                        <div class="pipeline-node-label">L0</div>
                        <div class="pipeline-node-name">Normalize</div>
                        <div class="pipeline-node-desc">Strip encoding tricks</div>
                    </div>
                    <div class="pipeline-arrow" aria-hidden="true">&#8594;</div>
                    <div class="pipeline-node node-blocked">
                        <div class="pipeline-node-label">L1</div>
                        <div class="pipeline-node-name">Classify</div>
                        <div class="pipeline-node-desc">ML injection detection</div>
                    </div>
                    <div class="pipeline-arrow" aria-hidden="true">&#8594;</div>
                    <div class="pipeline-node node-blocked">
                        <div class="pipeline-node-label">L3 Inbound</div>
                        <div class="pipeline-node-name">Block</div>
                        <div class="pipeline-node-desc">Pattern &amp; injection scan</div>
                    </div>
                    <div class="pipeline-arrow" aria-hidden="true">&#8594;</div>
                    <div class="pipeline-node node-blocked">
                        <div class="pipeline-node-label">L4</div>
                        <div class="pipeline-node-name">Multi-Turn</div>
                        <div class="pipeline-node-desc">Cross-turn risk scoring</div>
                    </div>
                    <div class="pipeline-arrow" aria-hidden="true">&#8594;</div>
                    <div class="pipeline-node node-end">
                        <div class="pipeline-node-name">LLM Provider</div>
                        <div class="pipeline-node-desc">OpenAI, Anthropic, etc.</div>
                    </div>
                </div>
                <div class="pipeline-row-label">Response</div>
                <div class="pipeline-row">
                    <div class="pipeline-node node-start">
                        <div class="pipeline-node-name">Your App</div>
                        <div class="pipeline-node-desc">Clean response</div>
                    </div>
                    <div class="pipeline-arrow" aria-hidden="true">&#8592;</div>
                    <div class="pipeline-node">
                        <div class="pipeline-node-label">L5a</div>
                        <div class="pipeline-node-name">Redact</div>
                        <div class="pipeline-node-desc">Strip secrets from output</div>
                    </div>
                    <div class="pipeline-arrow" aria-hidden="true">&#8592;</div>
                    <div class="pipeline-node node-blocked">
                        <div class="pipeline-node-label">L3 Outbound</div>
                        <div class="pipeline-node-name">Constrain</div>
                        <div class="pipeline-node-desc">Tool &amp; action limits</div>
                    </div>
                    <div class="pipeline-arrow" aria-hidden="true">&#8592;</div>
                    <div class="pipeline-node node-end">
                        <div class="pipeline-node-name">LLM Provider</div>
                        <div class="pipeline-node-desc">Returns response</div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Config -->
    <section id="config">
        <div class="container">
            <p class="section-label">Config-Driven</p>
            <h2>Define your security policy in YAML</h2>
            <p class="section-desc">Write a YAML policy, call <code>parapet.init()</code> before your first HTTP client, and every request is scanned.</p>
            <figure class="code-block" aria-labelledby="code-filename">
                <div class="code-header">
                    <span class="code-filename" id="code-filename">parapet.yaml</span>
                    <span class="code-lang">yaml</span>
                </div>
                <pre><code><span class="syn-key">parapet</span>: <span class="syn-val">v1</span>

<span class="syn-comment"># Block known injection patterns</span>
<span class="syn-key">block_patterns</span>:
  - <span class="syn-str">"ignore previous instructions"</span>
  - <span class="syn-str">"ignore all previous"</span>
  - <span class="syn-str">"DAN mode enabled"</span>
  - <span class="syn-str">"jailbreak"</span>

<span class="syn-comment"># Tool policies: default-deny, allowlist what you need</span>
<span class="syn-key">tools</span>:
  <span class="syn-key">_default</span>:
    <span class="syn-key">allowed</span>: <span class="syn-val">false</span>
  <span class="syn-key">read_file</span>:
    <span class="syn-key">allowed</span>: <span class="syn-val">true</span>
    <span class="syn-key">trust</span>: <span class="syn-val">untrusted</span>
    <span class="syn-key">constraints</span>:
      <span class="syn-key">path</span>:
        <span class="syn-key">not_contains</span>: [<span class="syn-danger">"../"</span>, <span class="syn-danger">"..\\"</span>]
  <span class="syn-key">exec_command</span>:
    <span class="syn-key">allowed</span>: <span class="syn-val">false</span>

<span class="syn-comment"># Redact secrets from LLM output</span>
<span class="syn-key">sensitive_patterns</span>:
  - <span class="syn-str">"sk-[a-zA-Z0-9]{20,}"</span>
  - <span class="syn-str">"-----BEGIN.*PRIVATE KEY-----"</span></code></pre>
            </figure>
        </div>
    </section>

    <!-- Quickstart -->
    <section id="quickstart">
        <div class="container">
            <p class="section-label">Quickstart</p>
            <h2>Five minutes to your first blocked attack</h2>
            <div class="steps">
                <div class="step">
                    <div class="step-number">Step 1</div>
                    <h3>Install</h3>
                    <p>Parapet works with any OpenAI-compatible provider.</p>
                    <code>pip install parapet</code>
                </div>
                <div class="step">
                    <div class="step-number">Step 2</div>
                    <h3>Configure</h3>
                    <p>Create a YAML file with one line. All six security layers active by default.</p>
                    <code>parapet: v1</code>
                </div>
                <div class="step">
                    <div class="step-number">Step 3</div>
                    <h3>Init</h3>
                    <p>One call before your first HTTP client. Every LLM request is scanned from that point on.</p>
                    <code>parapet.init("parapet.yaml")</code>
                </div>
            </div>
        </div>
    </section>

    <!-- Architecture -->
    <section id="architecture">
        <div class="container">
            <p class="section-label">Architecture</p>
            <h2>Transparent interception, minimal integration</h2>
            <div class="arch-diagram">
                <div class="arch-box">
                    <div class="arch-box-label">Your App</div>
                    <div class="arch-box-name">Python + httpx</div>
                </div>
                <div class="arch-arrow" aria-hidden="true">&#8594;</div>
                <div class="arch-box arch-parapet">
                    <div class="arch-box-label">Parapet SDK</div>
                    <div class="arch-box-name">Intercept &amp; Scan</div>
                </div>
                <div class="arch-arrow" aria-hidden="true">&#8594;</div>
                <div class="arch-box">
                    <div class="arch-box-label">Parapet Engine</div>
                    <div class="arch-box-name">Rust (fast path)</div>
                </div>
                <div class="arch-arrow" aria-hidden="true">&#8594;</div>
                <div class="arch-box">
                    <div class="arch-box-label">LLM Provider</div>
                    <div class="arch-box-name">OpenAI / Anthropic / etc.</div>
                </div>
            </div>
            <p class="arch-desc">Call <code>parapet.init("parapet.yaml")</code> before creating HTTP clients. The SDK monkey-patches <code>httpx</code>, the Rust engine runs all security layers in microseconds, and every LLM request is scanned transparently.</p>
        </div>
    </section>

    <!-- Features -->
    <section id="features">
        <div class="container">
            <p class="section-label">Defense Layers</p>
            <h2>What Parapet catches</h2>
            <div class="features-grid">
                <div class="feature">
                    <h3>ML Classifier (L1)</h3>
                    <p>Trained character n-gram SVM compiled into the binary. 98.6% F1 on 25K eval cases, sub-microsecond inference. Catches injection attempts that slip past pattern matching — no LLM call needed.</p>
                </div>
                <div class="feature">
                    <h3>Pattern Matching (L3)</h3>
                    <p>Regex patterns across 10 attack categories: instruction override, role hijacking, jailbreaks, system prompt extraction, privilege escalation, exfiltration. Scanned after Unicode normalization to defeat encoding tricks.</p>
                </div>
                <div class="feature">
                    <h3>Tool Abuse</h3>
                    <p>Per-tool constraints on arguments. Block path traversal in file tools, dangerous commands in shell tools, SSRF in web tools. Allowlists and denylists per tool name.</p>
                </div>
                <div class="feature">
                    <h3>Data Exfiltration</h3>
                    <p>Redact API keys, private keys, and secrets from LLM output. Regex-based pattern matching catches keys even if the model tries to encode or obfuscate them.</p>
                </div>
                <div class="feature">
                    <h3>Multi-Turn Attacks</h3>
                    <p>Cross-turn risk scoring detects attacks distributed across conversation turns: instruction seeding, role confusion escalation, resampling, and authority claim buildup. Peak + accumulation scoring — no LLM classifier needed.</p>
                </div>
                <div class="feature">
                    <h3>Canary Tokens</h3>
                    <p>Inject canary strings into system prompts. If they appear in output, your system prompt is leaking. Detect exfiltration attempts that bypass pattern matching.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Trust / Research -->
    <section id="research">
        <div class="container">
            <p class="section-label">Research-Backed</p>
            <h2>Built on the literature, not on vibes</h2>
            <p class="section-desc">Parapet's defense layers are grounded in published academic research on LLM security, prompt injection, and adversarial attacks on language models. Our multi-turn scoring formula — <em>peak + accumulation</em> — achieves 90.8% recall at 1.20% FPR on 10,654 conversations, without invoking an LLM. Read the paper: <a href="https://arxiv.org/abs/2602.11247">arXiv:2602.11247</a>.</p>
            <div class="trust-badges">
                <div class="trust-badge">
                    <div class="trust-badge-icon" aria-hidden="true"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"><path d="M2 3h6a4 4 0 0 1 4 4v14a3 3 0 0 0-3-3H2z"/><path d="M22 3h-6a4 4 0 0 0-4 4v14a3 3 0 0 1 3-3h7z"/></svg></div>
                    <div class="trust-badge-text">
                        <strong>Research-Grounded</strong>
                        Defense layers informed by the literature on prompt injection and adversarial attacks
                    </div>
                </div>
                <div class="trust-badge">
                    <div class="trust-badge-icon" aria-hidden="true"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"><rect x="3" y="11" width="18" height="11" rx="2" ry="2"/><path d="M7 11V7a5 5 0 0 1 10 0v4"/></svg></div>
                    <div class="trust-badge-text">
                        <strong>Open Source</strong>
                        Free deterministic layers, self-hosted, no data leaves your infrastructure
                    </div>
                </div>
                <div class="trust-badge">
                    <div class="trust-badge-icon" aria-hidden="true"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"><polygon points="13 2 3 14 12 14 11 22 21 10 12 10 13 2"/></svg></div>
                    <div class="trust-badge-text">
                        <strong>Rust Engine</strong>
                        Microsecond scanning on the fast path, no latency added to your requests
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- CTA -->
    <section class="cta-section" id="cta">
        <div class="container">
            <h2>Your LLM deserves a wall</h2>
            <p>Parapet is free, open source, and takes five minutes to set up.</p>
            <div class="hero-ctas">
                <a href="https://github.com/Parapet-Tech/parapet" class="btn btn-primary">View on GitHub</a>
                <a href="#quickstart" class="btn btn-secondary">Read the Quickstart</a>
            </div>
        </div>
    </section>

    </main>

    <!-- Footer -->
    <footer>
        <p>
            <a href="https://github.com/Parapet-Tech/parapet">GitHub</a> &middot;
            <a href="mailto:contact@parapet.tech">Contact</a> &middot;
            Apache 2.0 License
        </p>
    </footer>

</body>
</html>
